{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity: Build an LSTM to build a classifier for the Human Activity Recognition Using Smartphones Dataset #\n",
    "\n",
    "Adapted from https://github.com/servomac/Human-Activity-Recognition/\n",
    "\n",
    "Dataset information at https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones#\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All our imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from matplotlib.pyplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you run into any errors running the cell above, you may need to install a package using !pip install ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you already have it!\n"
     ]
    }
   ],
   "source": [
    "# Download the data: Only run this cell the first time\n",
    "import wget\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "\n",
    "#This is going to take a little while\n",
    "if not os.path.isdir(\"UCI HAR Dataset\"):\n",
    "    print(\"downloading\")\n",
    "    wget.download(\"http://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI HAR Dataset.zip\")\n",
    "    \n",
    "    with zipfile.ZipFile(\"UCI HAR Dataset.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"\")\n",
    "        \n",
    "    print(\"done\")\n",
    "    \n",
    "else:\n",
    "    print(\"you already have it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is helper code from the github repo.\n",
    "#No need to edit this, but it's helpful to glance through this code to see what it does\n",
    "\n",
    "DATADIR = 'UCI HAR Dataset' \n",
    "\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]\n",
    "\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'{DATADIR}/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).values\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))\n",
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'{DATADIR}/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).values\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])\n",
    "\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our LSTM model ##\n",
    "\n",
    "This is where the important stuff happens. Try to understand everything happening here, and experiment with changing it once you've got the basic method working.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data and splits into training and test sets, where X is input and Y is output\n",
    "X_train, X_test, Y_train, Y_test = load_data()\n",
    "\n",
    "#Compute some information from the data, which we need to set up the model\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9)\n"
     ]
    }
   ],
   "source": [
    "#After loading data, it's always a good idea to get a feel for what is in the data \n",
    "\n",
    "#For instance, we can use np.shape() to look at the shape of our examples\n",
    "print(np.shape(X_train)) #this shows us we have 7352 training examples, where each input is 128x9 (9 channels of 128 samples each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b9383836d0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We can peek at an individual example\n",
    "exampleNumber = 0\n",
    "channelNumber = 3\n",
    "plot(np.transpose(X_train[exampleNumber])[channelNumber])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 6)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(Y_train)) #and we have a 6-dimensional output for each one of our 7352 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "#We're using a \"one-hot\" encoding, which means that \"1 0 0 0 0 0\" means \"class 1\", \"0 1 0 0 0 0\" means class 2, and so on\n",
    "print(Y_train[0]) #Prints the 6-dimensional output for the first training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "460/460 [==============================] - 12s 23ms/step - loss: 1.1788 - accuracy: 0.5092 - val_loss: 0.9462 - val_accuracy: 0.6050\n",
      "Epoch 2/5\n",
      "460/460 [==============================] - 10s 22ms/step - loss: 0.8037 - accuracy: 0.6496 - val_loss: 0.7435 - val_accuracy: 0.7041\n",
      "Epoch 3/5\n",
      "460/460 [==============================] - 10s 22ms/step - loss: 0.7917 - accuracy: 0.6662 - val_loss: 0.7731 - val_accuracy: 0.6630\n",
      "Epoch 4/5\n",
      "460/460 [==============================] - 10s 22ms/step - loss: 0.6904 - accuracy: 0.6995 - val_loss: 0.7168 - val_accuracy: 0.7445\n",
      "Epoch 5/5\n",
      "460/460 [==============================] - 10s 22ms/step - loss: 0.5720 - accuracy: 0.7739 - val_loss: 0.5553 - val_accuracy: 0.8045\n",
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 492       18         0        0                   0   \n",
      "SITTING                  2      366       119        3                   0   \n",
      "STANDING                 0       76       450        2                   0   \n",
      "WALKING                  0        1         1      422                  29   \n",
      "WALKING_DOWNSTAIRS       0        0         0      120                 292   \n",
      "WALKING_UPSTAIRS         0        0         2       87                  33   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                            1  \n",
      "STANDING                           4  \n",
      "WALKING                           43  \n",
      "WALKING_DOWNSTAIRS                 8  \n",
      "WALKING_UPSTAIRS                 349  \n"
     ]
    }
   ],
   "source": [
    "# This is where things get fun.\n",
    "\n",
    "# Set some parameters to control training\n",
    "# The number of epochs is the number of passes through the training data to make before you stop training\n",
    "epochs = 5 # Play with this; might especially want to increase it once you know things are basically working\n",
    "\n",
    "# The batch size is the number of examples to use to compute the gradient before updating the weights\n",
    "# If batch_size is the same as the training set size, we use the whole training set every time. This is called \"batch gradient descent\"\n",
    "# If batch_size is 1 then this is \"stochastic gradient descent\"\n",
    "# If batch_size is something in between, then this is called \"mini-batch\" gradient descent\n",
    "# Each choice will have different tradeoffs in terms of training time and ultimate accuracy, but there's no \"right way\" to do it\n",
    "# For more info, see https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/#:~:text=The%20batch%20size%20is%20a%20hyperparameter%20that%20defines%20the%20number,updating%20the%20internal%20model%20parameters.&text=When%20the%20batch%20size%20is,called%20mini%2Dbatch%20gradient%20descent. \n",
    "batch_size = 16 #You might want to play with this too\n",
    "\n",
    "#How many hidden neurons do we want?\n",
    "n_hidden = 32 #Feel free to change this\n",
    "\n",
    "\n",
    "#This is the Keras code for specifying the network architecture:\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) #an LSTM layer\n",
    "model.add(Dropout(0.5)) #This is a method to try to prevent overfitting. See more at https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "model.add(Dense(n_classes, activation='sigmoid')) #a plain \"dense\" layer comes after the LSTM layer\n",
    "\n",
    "#This line specifies how to train this network.\n",
    "#You might want to play with these 3 values\n",
    "#see more at https://keras.io/api/losses/, https://keras.io/api/optimizers/, https://keras.io/api/metrics/\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#This line of code actually trains the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "460/460 [==============================] - 16s 24ms/step - loss: 1.1258 - accuracy: 0.5324 - val_loss: 0.8067 - val_accuracy: 0.6295\n",
      "Epoch 2/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.7920 - accuracy: 0.6355 - val_loss: 0.7596 - val_accuracy: 0.6800\n",
      "Epoch 3/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.6784 - accuracy: 0.6835 - val_loss: 0.6945 - val_accuracy: 0.6875\n",
      "Epoch 4/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.6105 - accuracy: 0.7442 - val_loss: 0.7143 - val_accuracy: 0.7014\n",
      "Epoch 5/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.5786 - accuracy: 0.7599 - val_loss: 0.5641 - val_accuracy: 0.7740\n",
      "Epoch 6/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.4783 - accuracy: 0.8025 - val_loss: 0.6870 - val_accuracy: 0.7231\n",
      "Epoch 7/50\n",
      "460/460 [==============================] - 11s 24ms/step - loss: 0.4297 - accuracy: 0.8387 - val_loss: 0.4652 - val_accuracy: 0.8151\n",
      "Epoch 8/50\n",
      "460/460 [==============================] - 11s 24ms/step - loss: 0.3326 - accuracy: 0.8972 - val_loss: 0.4451 - val_accuracy: 0.8276\n",
      "Epoch 9/50\n",
      "460/460 [==============================] - 11s 24ms/step - loss: 0.2676 - accuracy: 0.9202 - val_loss: 0.4997 - val_accuracy: 0.8517\n",
      "Epoch 10/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.3415 - accuracy: 0.8955 - val_loss: 0.5806 - val_accuracy: 0.7611\n",
      "Epoch 11/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.3362 - accuracy: 0.8762 - val_loss: 0.4073 - val_accuracy: 0.8768\n",
      "Epoch 12/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.2086 - accuracy: 0.9359 - val_loss: 0.4211 - val_accuracy: 0.8812\n",
      "Epoch 13/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1741 - accuracy: 0.9423 - val_loss: 0.4247 - val_accuracy: 0.8778\n",
      "Epoch 14/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.3129 - accuracy: 0.8958 - val_loss: 0.4216 - val_accuracy: 0.8459\n",
      "Epoch 15/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.2231 - accuracy: 0.9252 - val_loss: 0.4267 - val_accuracy: 0.8768\n",
      "Epoch 16/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.3625 - accuracy: 0.8658 - val_loss: 0.3202 - val_accuracy: 0.8833\n",
      "Epoch 17/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.2371 - accuracy: 0.9215 - val_loss: 0.7409 - val_accuracy: 0.7462\n",
      "Epoch 18/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.2344 - accuracy: 0.9166 - val_loss: 0.3486 - val_accuracy: 0.8856\n",
      "Epoch 19/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1919 - accuracy: 0.9376 - val_loss: 0.4142 - val_accuracy: 0.8965\n",
      "Epoch 20/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.2376 - accuracy: 0.9238 - val_loss: 0.4110 - val_accuracy: 0.8409\n",
      "Epoch 21/50\n",
      "460/460 [==============================] - 11s 24ms/step - loss: 0.2080 - accuracy: 0.9237 - val_loss: 0.3660 - val_accuracy: 0.8850\n",
      "Epoch 22/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1676 - accuracy: 0.9412 - val_loss: 0.3003 - val_accuracy: 0.8955\n",
      "Epoch 23/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1860 - accuracy: 0.9339 - val_loss: 0.3989 - val_accuracy: 0.8833\n",
      "Epoch 24/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1494 - accuracy: 0.9429 - val_loss: 0.3836 - val_accuracy: 0.8989\n",
      "Epoch 25/50\n",
      "460/460 [==============================] - 11s 24ms/step - loss: 0.1551 - accuracy: 0.9407 - val_loss: 0.4479 - val_accuracy: 0.8717\n",
      "Epoch 26/50\n",
      "460/460 [==============================] - 11s 24ms/step - loss: 0.1778 - accuracy: 0.9289 - val_loss: 0.3506 - val_accuracy: 0.9070\n",
      "Epoch 27/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1551 - accuracy: 0.9419 - val_loss: 0.3078 - val_accuracy: 0.9016\n",
      "Epoch 28/50\n",
      "460/460 [==============================] - 11s 24ms/step - loss: 0.1417 - accuracy: 0.9459 - val_loss: 0.3093 - val_accuracy: 0.9050\n",
      "Epoch 29/50\n",
      "460/460 [==============================] - 11s 24ms/step - loss: 0.1526 - accuracy: 0.9445 - val_loss: 0.3732 - val_accuracy: 0.9057\n",
      "Epoch 30/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1455 - accuracy: 0.9438 - val_loss: 0.2934 - val_accuracy: 0.9141\n",
      "Epoch 31/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1324 - accuracy: 0.9501 - val_loss: 0.3476 - val_accuracy: 0.9114\n",
      "Epoch 32/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1295 - accuracy: 0.9495 - val_loss: 0.3456 - val_accuracy: 0.9077\n",
      "Epoch 33/50\n",
      "460/460 [==============================] - 11s 25ms/step - loss: 0.2319 - accuracy: 0.9275 - val_loss: 0.3284 - val_accuracy: 0.8989\n",
      "Epoch 34/50\n",
      "460/460 [==============================] - 12s 25ms/step - loss: 0.1521 - accuracy: 0.9479 - val_loss: 0.3379 - val_accuracy: 0.8979\n",
      "Epoch 35/50\n",
      "460/460 [==============================] - 12s 26ms/step - loss: 0.2163 - accuracy: 0.9393 - val_loss: 0.3517 - val_accuracy: 0.9104\n",
      "Epoch 36/50\n",
      "460/460 [==============================] - 11s 25ms/step - loss: 0.2002 - accuracy: 0.9335 - val_loss: 0.2891 - val_accuracy: 0.9094\n",
      "Epoch 37/50\n",
      "460/460 [==============================] - 11s 25ms/step - loss: 0.1551 - accuracy: 0.9412 - val_loss: 0.3503 - val_accuracy: 0.9097\n",
      "Epoch 38/50\n",
      "460/460 [==============================] - 11s 25ms/step - loss: 0.1579 - accuracy: 0.9419 - val_loss: 0.4203 - val_accuracy: 0.8972\n",
      "Epoch 39/50\n",
      "460/460 [==============================] - 12s 26ms/step - loss: 0.2450 - accuracy: 0.9211 - val_loss: 0.4600 - val_accuracy: 0.8863\n",
      "Epoch 40/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1515 - accuracy: 0.9423 - val_loss: 0.4284 - val_accuracy: 0.8972\n",
      "Epoch 41/50\n",
      "460/460 [==============================] - 11s 24ms/step - loss: 0.1347 - accuracy: 0.9472 - val_loss: 0.4452 - val_accuracy: 0.8989\n",
      "Epoch 42/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1431 - accuracy: 0.9459 - val_loss: 0.4689 - val_accuracy: 0.8965\n",
      "Epoch 43/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1407 - accuracy: 0.9441 - val_loss: 0.4214 - val_accuracy: 0.8901\n",
      "Epoch 44/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1266 - accuracy: 0.9531 - val_loss: 0.4244 - val_accuracy: 0.9006\n",
      "Epoch 45/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1486 - accuracy: 0.9437 - val_loss: 0.3775 - val_accuracy: 0.9087\n",
      "Epoch 46/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1441 - accuracy: 0.9491 - val_loss: 0.4704 - val_accuracy: 0.9046\n",
      "Epoch 47/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1765 - accuracy: 0.9358 - val_loss: 0.3820 - val_accuracy: 0.9111\n",
      "Epoch 48/50\n",
      "460/460 [==============================] - 11s 24ms/step - loss: 0.1421 - accuracy: 0.9427 - val_loss: 0.3922 - val_accuracy: 0.9063\n",
      "Epoch 49/50\n",
      "460/460 [==============================] - 11s 24ms/step - loss: 0.1507 - accuracy: 0.9422 - val_loss: 0.4762 - val_accuracy: 0.8887\n",
      "Epoch 50/50\n",
      "460/460 [==============================] - 11s 23ms/step - loss: 0.1623 - accuracy: 0.9374 - val_loss: 0.4366 - val_accuracy: 0.9040\n",
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0        27        0                   0   \n",
      "SITTING                  0      361       126        0                   0   \n",
      "STANDING                 0       63       465        4                   0   \n",
      "WALKING                  1        0         1      464                  29   \n",
      "WALKING_DOWNSTAIRS       0        0         0        1                 419   \n",
      "WALKING_UPSTAIRS         0        1         0       19                   6   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            4  \n",
      "STANDING                           0  \n",
      "WALKING                            1  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 445  \n"
     ]
    }
   ],
   "source": [
    "# This is where things get fun.\n",
    "\n",
    "# Set some parameters to control training\n",
    "# The number of epochs is the number of passes through the training data to make before you stop training\n",
    "epochs = 50 # Play with this; might especially want to increase it once you know things are basically working\n",
    "\n",
    "# The batch size is the number of examples to use to compute the gradient before updating the weights\n",
    "# If batch_size is the same as the training set size, we use the whole training set every time. This is called \"batch gradient descent\"\n",
    "# If batch_size is 1 then this is \"stochastic gradient descent\"\n",
    "# If batch_size is something in between, then this is called \"mini-batch\" gradient descent\n",
    "# Each choice will have different tradeoffs in terms of training time and ultimate accuracy, but there's no \"right way\" to do it\n",
    "# For more info, see https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/#:~:text=The%20batch%20size%20is%20a%20hyperparameter%20that%20defines%20the%20number,updating%20the%20internal%20model%20parameters.&text=When%20the%20batch%20size%20is,called%20mini%2Dbatch%20gradient%20descent. \n",
    "batch_size = 16 #You might want to play with this too\n",
    "\n",
    "#How many hidden neurons do we want?\n",
    "n_hidden = 32 #Feel free to change this\n",
    "\n",
    "\n",
    "#This is the Keras code for specifying the network architecture:\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) #an LSTM layer\n",
    "model.add(Dropout(0.5)) #This is a method to try to prevent overfitting. See more at https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "model.add(Dense(n_classes, activation='sigmoid')) #a plain \"dense\" layer comes after the LSTM layer\n",
    "\n",
    "#This line specifies how to train this network.\n",
    "#You might want to play with these 3 values\n",
    "#see more at https://keras.io/api/losses/, https://keras.io/api/optimizers/, https://keras.io/api/metrics/\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#This line of code actually trains the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Next steps: Experiment!\n",
    "\n",
    "### 1. Try digging into & tweaking the results above. ###\n",
    "\n",
    "* What happens with a different optimizer?\n",
    "* Can you edit the code to use a validation set with early stopping, as well?\n",
    "* What happens to the training accuracy, test/validation accuracy, and training time if you change the number of training examples?\n",
    "* What happens if you change the dropout?\n",
    "* Can you visualise this data (e.g., in Python using matplotlib, or in Excel) to get a sense of what it looks like?\n",
    "* What else might you print each epoch, instead of just accuracy and loss?\n",
    "* What else might you do if you were trying to release a commercial product that did this classification? How would you test it? How else might you edit the code to train your neural network? What would your main considerations be in deploying it?\n",
    "\n",
    "### 2. Do more reading about all the options available to you in Keras ###\n",
    "* https://keras.io/api/optimizers/\n",
    "* https://keras.io/api/metrics/\n",
    "* https://keras.io/api/losses/\n",
    "* Use the `?` operation in Python to learn more about your options in code (e.g., `?model.compile`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "230/230 [==============================] - 8s 30ms/step - loss: 1.3107 - accuracy: 0.4452 - val_loss: 1.0011 - val_accuracy: 0.5487\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.8163 - accuracy: 0.6367 - val_loss: 0.7904 - val_accuracy: 0.6430\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.7977 - accuracy: 0.6566 - val_loss: 0.7833 - val_accuracy: 0.6834\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.7213 - accuracy: 0.6900 - val_loss: 0.7253 - val_accuracy: 0.6997\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.5735 - accuracy: 0.7677 - val_loss: 0.6415 - val_accuracy: 0.7625\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.5102 - accuracy: 0.8020 - val_loss: 0.6481 - val_accuracy: 0.7377\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.4566 - accuracy: 0.8343 - val_loss: 0.5338 - val_accuracy: 0.8368\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3407 - accuracy: 0.8862 - val_loss: 0.4581 - val_accuracy: 0.8456\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2856 - accuracy: 0.9083 - val_loss: 0.5103 - val_accuracy: 0.8409\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2610 - accuracy: 0.9163 - val_loss: 0.4421 - val_accuracy: 0.8588\n",
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  1      360       127        1                   0   \n",
      "STANDING                 0       65       464        2                   0   \n",
      "WALKING                  3        3         1      428                  42   \n",
      "WALKING_DOWNSTAIRS       0        0         0       41                 332   \n",
      "WALKING_UPSTAIRS         1        0         0       18                  15   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                            2  \n",
      "STANDING                           1  \n",
      "WALKING                           19  \n",
      "WALKING_DOWNSTAIRS                47  \n",
      "WALKING_UPSTAIRS                 437  \n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "n_hidden = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) #an LSTM layer\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)\n",
    "\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `Sequential()` not found.\n"
     ]
    }
   ],
   "source": [
    "?Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "?model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "?model.compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `compile()` not found.\n"
     ]
    }
   ],
   "source": [
    "?compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `fit()` not found.\n"
     ]
    }
   ],
   "source": [
    "?fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "230/230 [==============================] - 9s 35ms/step - loss: 1.2278 - accuracy: 0.4706 - val_loss: 0.9957 - val_accuracy: 0.5304\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 8s 33ms/step - loss: 0.8474 - accuracy: 0.6413 - val_loss: 0.7795 - val_accuracy: 0.6742\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 8s 33ms/step - loss: 0.6549 - accuracy: 0.7356 - val_loss: 0.6689 - val_accuracy: 0.7296\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 8s 33ms/step - loss: 0.6572 - accuracy: 0.7542 - val_loss: 1.0337 - val_accuracy: 0.6250\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 8s 33ms/step - loss: 0.7776 - accuracy: 0.7156 - val_loss: 0.5492 - val_accuracy: 0.8137\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 8s 33ms/step - loss: 0.4638 - accuracy: 0.8456 - val_loss: 0.5496 - val_accuracy: 0.8079\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 8s 33ms/step - loss: 0.2954 - accuracy: 0.9101 - val_loss: 0.3761 - val_accuracy: 0.8660\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 8s 34ms/step - loss: 0.2944 - accuracy: 0.9083 - val_loss: 0.3931 - val_accuracy: 0.8677\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 8s 34ms/step - loss: 0.2527 - accuracy: 0.9200 - val_loss: 0.3469 - val_accuracy: 0.8768\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 8s 33ms/step - loss: 0.2052 - accuracy: 0.9317 - val_loss: 0.2851 - val_accuracy: 0.8941\n",
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 519        0         0        0                   0   \n",
      "SITTING                  2      407        78        3                   0   \n",
      "STANDING                 0      111       416        3                   0   \n",
      "WALKING                  0        0         0      466                  12   \n",
      "WALKING_DOWNSTAIRS       0        0         0       16                 394   \n",
      "WALKING_UPSTAIRS         1        0         0       13                  24   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            18  \n",
      "SITTING                            1  \n",
      "STANDING                           2  \n",
      "WALKING                           18  \n",
      "WALKING_DOWNSTAIRS                10  \n",
      "WALKING_UPSTAIRS                 433  \n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "n_hidden = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) #an LSTM layer\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)\n",
    "\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "230/230 [==============================] - 7s 26ms/step - loss: 1.0530 - accuracy: 0.5442 - val_loss: 0.8076 - val_accuracy: 0.6176\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.6831 - accuracy: 0.7237 - val_loss: 0.6654 - val_accuracy: 0.8154\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.4819 - accuracy: 0.8526 - val_loss: 0.6475 - val_accuracy: 0.8093\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.5985 - accuracy: 0.8006 - val_loss: 0.8130 - val_accuracy: 0.6607\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.4257 - accuracy: 0.8576 - val_loss: 0.5537 - val_accuracy: 0.8504\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3157 - accuracy: 0.8996 - val_loss: 0.5350 - val_accuracy: 0.8772\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2925 - accuracy: 0.9029 - val_loss: 0.3960 - val_accuracy: 0.8860\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2182 - accuracy: 0.9289 - val_loss: 0.4507 - val_accuracy: 0.8897\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3037 - accuracy: 0.8923 - val_loss: 0.3998 - val_accuracy: 0.8887\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1882 - accuracy: 0.9328 - val_loss: 0.4422 - val_accuracy: 0.8931\n",
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      361       124        1                   0   \n",
      "STANDING                 0       59       471        2                   0   \n",
      "WALKING                  0        0         1      422                  49   \n",
      "WALKING_DOWNSTAIRS       0        0         0        1                 412   \n",
      "WALKING_UPSTAIRS         0        0         0        6                  36   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            5  \n",
      "STANDING                           0  \n",
      "WALKING                           24  \n",
      "WALKING_DOWNSTAIRS                 7  \n",
      "WALKING_UPSTAIRS                 429  \n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "n_hidden = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) #an LSTM layer\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)\n",
    "\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "230/230 [==============================] - 7s 25ms/step - loss: 1.2574 - accuracy: 0.4771 - val_loss: 1.0466 - val_accuracy: 0.5623\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.8602 - accuracy: 0.6454 - val_loss: 0.8068 - val_accuracy: 0.6739\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.7150 - accuracy: 0.6959 - val_loss: 0.6983 - val_accuracy: 0.7333\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.6294 - accuracy: 0.7644 - val_loss: 0.9484 - val_accuracy: 0.6342\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.5171 - accuracy: 0.8188 - val_loss: 0.5918 - val_accuracy: 0.8022\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.4277 - accuracy: 0.8610 - val_loss: 0.5111 - val_accuracy: 0.8202\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.3603 - accuracy: 0.8923 - val_loss: 0.5313 - val_accuracy: 0.8412\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.2956 - accuracy: 0.9108 - val_loss: 0.4846 - val_accuracy: 0.8561\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.2696 - accuracy: 0.9222 - val_loss: 0.5105 - val_accuracy: 0.8510\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.2423 - accuracy: 0.9294 - val_loss: 0.4331 - val_accuracy: 0.8795\n",
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  0      420        61        0                   0   \n",
      "STANDING                 0      125       403        4                   0   \n",
      "WALKING                  0        0         0      484                   9   \n",
      "WALKING_DOWNSTAIRS       0        0         0       26                 392   \n",
      "WALKING_UPSTAIRS         0        0         0       38                  50   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                           10  \n",
      "STANDING                           0  \n",
      "WALKING                            3  \n",
      "WALKING_DOWNSTAIRS                 2  \n",
      "WALKING_UPSTAIRS                 383  \n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "n_hidden = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) #an LSTM layer\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='RMSprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)\n",
    "\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "230/230 [==============================] - 7s 24ms/step - loss: 1.1951 - accuracy: 0.5166 - val_loss: 0.8916 - val_accuracy: 0.6783\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.7429 - accuracy: 0.6968 - val_loss: 0.7199 - val_accuracy: 0.6834\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.8200 - accuracy: 0.6483 - val_loss: 0.7651 - val_accuracy: 0.6600\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.6692 - accuracy: 0.6970 - val_loss: 0.6780 - val_accuracy: 0.7136\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.6063 - accuracy: 0.7359 - val_loss: 0.7217 - val_accuracy: 0.7319\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.5420 - accuracy: 0.7779 - val_loss: 0.5758 - val_accuracy: 0.7930\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.4093 - accuracy: 0.8630 - val_loss: 0.5201 - val_accuracy: 0.8297\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.4009 - accuracy: 0.8619 - val_loss: 0.5280 - val_accuracy: 0.8219\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.3040 - accuracy: 0.9040 - val_loss: 0.8351 - val_accuracy: 0.7299\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.3704 - accuracy: 0.8742 - val_loss: 0.5702 - val_accuracy: 0.7703\n",
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  0      374       109        3                   0   \n",
      "STANDING                 0       89       441        0                   0   \n",
      "WALKING                  0        0         1      480                  12   \n",
      "WALKING_DOWNSTAIRS       0        0         0      158                 260   \n",
      "WALKING_UPSTAIRS         0        0         3      243                  20   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                            5  \n",
      "STANDING                           2  \n",
      "WALKING                            3  \n",
      "WALKING_DOWNSTAIRS                 2  \n",
      "WALKING_UPSTAIRS                 205  \n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "n_hidden = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) #an LSTM layer\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)\n",
    "\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "230/230 [==============================] - 6s 21ms/step - loss: 1.2395 - accuracy: 0.4962 - val_loss: 1.4926 - val_accuracy: 0.4350\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 5s 20ms/step - loss: 1.0391 - accuracy: 0.5666 - val_loss: 1.4865 - val_accuracy: 0.2728\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 5s 20ms/step - loss: 1.5310 - accuracy: 0.3362 - val_loss: 1.3851 - val_accuracy: 0.4503\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 5s 20ms/step - loss: 1.2638 - accuracy: 0.4483 - val_loss: 1.2314 - val_accuracy: 0.5134\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 5s 20ms/step - loss: 1.1432 - accuracy: 0.5061 - val_loss: 1.1615 - val_accuracy: 0.5422\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 4s 20ms/step - loss: 1.0592 - accuracy: 0.5467 - val_loss: 1.3921 - val_accuracy: 0.4869\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 5s 20ms/step - loss: 1.0025 - accuracy: 0.5604 - val_loss: 1.4360 - val_accuracy: 0.4018\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.8846 - accuracy: 0.6234 - val_loss: 0.8008 - val_accuracy: 0.6685\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 5s 20ms/step - loss: 0.9228 - accuracy: 0.5947 - val_loss: 0.8148 - val_accuracy: 0.6563\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 5s 20ms/step - loss: 1.0019 - accuracy: 0.5637 - val_loss: 0.9135 - val_accuracy: 0.5806\n",
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 509        0         0       28                   0   \n",
      "SITTING                  0      141       347        3                   0   \n",
      "STANDING                 0        4       518       10                   0   \n",
      "WALKING                  0        4        45      410                  28   \n",
      "WALKING_DOWNSTAIRS       1        1        11      321                  63   \n",
      "WALKING_UPSTAIRS         1        1         7      371                  21   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            0  \n",
      "STANDING                           0  \n",
      "WALKING                            9  \n",
      "WALKING_DOWNSTAIRS                23  \n",
      "WALKING_UPSTAIRS                  70  \n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "n_hidden = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) #an LSTM layer\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)\n",
    "\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "230/230 [==============================] - 7s 26ms/step - loss: 1.2593 - accuracy: 0.4652 - val_loss: 1.1089 - val_accuracy: 0.5351\n",
      "Epoch 2/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 1.0542 - accuracy: 0.5507 - val_loss: 1.4520 - val_accuracy: 0.4293\n",
      "Epoch 3/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 1.0003 - accuracy: 0.5919 - val_loss: 1.0190 - val_accuracy: 0.6101\n",
      "Epoch 4/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.9342 - accuracy: 0.6099 - val_loss: 1.0929 - val_accuracy: 0.5677\n",
      "Epoch 5/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.8140 - accuracy: 0.6597 - val_loss: 0.8749 - val_accuracy: 0.6356\n",
      "Epoch 6/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.7204 - accuracy: 0.7002 - val_loss: 0.7034 - val_accuracy: 0.6797\n",
      "Epoch 7/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.8468 - accuracy: 0.6789 - val_loss: 0.7496 - val_accuracy: 0.7027\n",
      "Epoch 8/50\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.6162 - accuracy: 0.7538 - val_loss: 0.7320 - val_accuracy: 0.7027\n",
      "Epoch 9/50\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.6630 - accuracy: 0.7153 - val_loss: 0.8057 - val_accuracy: 0.6413\n",
      "Epoch 10/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.9251 - accuracy: 0.6296 - val_loss: 0.8932 - val_accuracy: 0.6023\n",
      "Epoch 11/50\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 1.0637 - accuracy: 0.5578 - val_loss: 1.2237 - val_accuracy: 0.4493\n",
      "Epoch 12/50\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 1.1235 - accuracy: 0.4963 - val_loss: 1.1349 - val_accuracy: 0.4818\n",
      "Epoch 13/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 1.0127 - accuracy: 0.5412 - val_loss: 1.0007 - val_accuracy: 0.5677\n",
      "Epoch 14/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 1.0165 - accuracy: 0.5789 - val_loss: 0.8834 - val_accuracy: 0.6074\n",
      "Epoch 15/50\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.9082 - accuracy: 0.6115 - val_loss: 0.9144 - val_accuracy: 0.6101\n",
      "Epoch 16/50\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.9470 - accuracy: 0.6061 - val_loss: 0.9903 - val_accuracy: 0.5433\n",
      "Epoch 17/50\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.9087 - accuracy: 0.6159 - val_loss: 0.8822 - val_accuracy: 0.6050\n",
      "Epoch 18/50\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.9062 - accuracy: 0.6027 - val_loss: 0.8970 - val_accuracy: 0.6016\n",
      "Epoch 19/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.8693 - accuracy: 0.6143 - val_loss: 0.8633 - val_accuracy: 0.5775\n",
      "Epoch 20/50\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.7933 - accuracy: 0.6472 - val_loss: 0.7652 - val_accuracy: 0.6461\n",
      "Epoch 21/50\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.7904 - accuracy: 0.6430 - val_loss: 0.7533 - val_accuracy: 0.6535\n",
      "Epoch 22/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 1.0284 - accuracy: 0.5622 - val_loss: 1.3493 - val_accuracy: 0.4659\n",
      "Epoch 23/50\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.9805 - accuracy: 0.5819 - val_loss: 0.8135 - val_accuracy: 0.6169\n",
      "Epoch 24/50\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.7625 - accuracy: 0.6402 - val_loss: 0.8178 - val_accuracy: 0.6532\n",
      "Epoch 25/50\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.7288 - accuracy: 0.6589 - val_loss: 0.8361 - val_accuracy: 0.6861\n",
      "Epoch 26/50\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 1.0479 - accuracy: 0.5643 - val_loss: 0.8227 - val_accuracy: 0.6403\n",
      "Epoch 27/50\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.9006 - accuracy: 0.6129 - val_loss: 0.8301 - val_accuracy: 0.6084\n",
      "Epoch 28/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.7937 - accuracy: 0.6567 - val_loss: 0.7323 - val_accuracy: 0.6919\n",
      "Epoch 29/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.6706 - accuracy: 0.7092 - val_loss: 0.7029 - val_accuracy: 0.7068\n",
      "Epoch 30/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.6439 - accuracy: 0.7335 - val_loss: 0.7952 - val_accuracy: 0.6566\n",
      "Epoch 31/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.6543 - accuracy: 0.7118 - val_loss: 0.6886 - val_accuracy: 0.6980\n",
      "Epoch 32/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.5444 - accuracy: 0.7695 - val_loss: 0.5650 - val_accuracy: 0.7591\n",
      "Epoch 33/50\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.4454 - accuracy: 0.8043 - val_loss: 0.5721 - val_accuracy: 0.7533\n",
      "Epoch 34/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.4255 - accuracy: 0.8145 - val_loss: 0.5600 - val_accuracy: 0.7716\n",
      "Epoch 35/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.3915 - accuracy: 0.8308 - val_loss: 0.5534 - val_accuracy: 0.7679\n",
      "Epoch 36/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.4007 - accuracy: 0.8387 - val_loss: 0.5503 - val_accuracy: 0.7808\n",
      "Epoch 37/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3582 - accuracy: 0.8594 - val_loss: 0.6212 - val_accuracy: 0.7401\n",
      "Epoch 38/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.3978 - accuracy: 0.8448 - val_loss: 0.5541 - val_accuracy: 0.8025\n",
      "Epoch 39/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.3809 - accuracy: 0.8541 - val_loss: 0.5205 - val_accuracy: 0.8032\n",
      "Epoch 40/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3534 - accuracy: 0.8609 - val_loss: 0.4795 - val_accuracy: 0.8151\n",
      "Epoch 41/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3191 - accuracy: 0.8690 - val_loss: 0.4890 - val_accuracy: 0.8018\n",
      "Epoch 42/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3361 - accuracy: 0.8641 - val_loss: 0.5466 - val_accuracy: 0.8073\n",
      "Epoch 43/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3399 - accuracy: 0.8611 - val_loss: 0.4624 - val_accuracy: 0.8358\n",
      "Epoch 44/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2836 - accuracy: 0.8931 - val_loss: 0.4689 - val_accuracy: 0.8303\n",
      "Epoch 45/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2667 - accuracy: 0.9003 - val_loss: 0.4756 - val_accuracy: 0.8354\n",
      "Epoch 46/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.4103 - accuracy: 0.8587 - val_loss: 1.6131 - val_accuracy: 0.5253\n",
      "Epoch 47/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.5494 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.8117\n",
      "Epoch 48/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3964 - accuracy: 0.8534 - val_loss: 0.4941 - val_accuracy: 0.8202\n",
      "Epoch 49/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3760 - accuracy: 0.8576 - val_loss: 0.4739 - val_accuracy: 0.8392\n",
      "Epoch 50/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3270 - accuracy: 0.8851 - val_loss: 0.4607 - val_accuracy: 0.8402\n",
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  0      410        79        0                   0   \n",
      "STANDING                 0      102       422        1                   0   \n",
      "WALKING                  0        0         0      414                  41   \n",
      "WALKING_DOWNSTAIRS       0        0         2       44                 367   \n",
      "WALKING_UPSTAIRS         0        0        18       77                  23   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                            2  \n",
      "STANDING                           7  \n",
      "WALKING                           41  \n",
      "WALKING_DOWNSTAIRS                 7  \n",
      "WALKING_UPSTAIRS                 353  \n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "n_hidden = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) #an LSTM layer\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)\n",
    "\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "230/230 [==============================] - 7s 26ms/step - loss: 1.2132 - accuracy: 0.5015 - val_loss: 1.0403 - val_accuracy: 0.5779\n",
      "Epoch 2/50\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.8188 - accuracy: 0.6684 - val_loss: 0.8099 - val_accuracy: 0.6854\n",
      "Epoch 3/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.7018 - accuracy: 0.7081 - val_loss: 0.7936 - val_accuracy: 0.7170\n",
      "Epoch 4/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.5401 - accuracy: 0.7783 - val_loss: 0.6250 - val_accuracy: 0.7631\n",
      "Epoch 5/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.5288 - accuracy: 0.7773 - val_loss: 0.5879 - val_accuracy: 0.7760\n",
      "Epoch 6/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.4784 - accuracy: 0.7935 - val_loss: 0.9044 - val_accuracy: 0.6468\n",
      "Epoch 7/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.5841 - accuracy: 0.7456 - val_loss: 0.6326 - val_accuracy: 0.7380\n",
      "Epoch 8/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.4894 - accuracy: 0.7952 - val_loss: 0.5925 - val_accuracy: 0.7645\n",
      "Epoch 9/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.4092 - accuracy: 0.8335 - val_loss: 0.5635 - val_accuracy: 0.7991\n",
      "Epoch 10/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.4197 - accuracy: 0.8526 - val_loss: 0.4786 - val_accuracy: 0.8537\n",
      "Epoch 11/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3299 - accuracy: 0.8860 - val_loss: 0.3882 - val_accuracy: 0.8544\n",
      "Epoch 12/50\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.2846 - accuracy: 0.9086 - val_loss: 0.3622 - val_accuracy: 0.8789\n",
      "Epoch 13/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2386 - accuracy: 0.9187 - val_loss: 0.6815 - val_accuracy: 0.7808\n",
      "Epoch 14/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2144 - accuracy: 0.9306 - val_loss: 0.3130 - val_accuracy: 0.8941\n",
      "Epoch 15/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3644 - accuracy: 0.8872 - val_loss: 0.5998 - val_accuracy: 0.7689\n",
      "Epoch 16/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.4252 - accuracy: 0.8240 - val_loss: 0.4448 - val_accuracy: 0.8117\n",
      "Epoch 17/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3441 - accuracy: 0.8448 - val_loss: 0.4178 - val_accuracy: 0.8297\n",
      "Epoch 18/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.3745 - accuracy: 0.8366 - val_loss: 0.4104 - val_accuracy: 0.8334\n",
      "Epoch 19/50\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.3625 - accuracy: 0.8508 - val_loss: 0.3888 - val_accuracy: 0.8385\n",
      "Epoch 20/50\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2977 - accuracy: 0.8727 - val_loss: 0.3674 - val_accuracy: 0.8565\n",
      "Epoch 21/50\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2613 - accuracy: 0.8947 - val_loss: 0.3678 - val_accuracy: 0.8643\n",
      "Epoch 22/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2249 - accuracy: 0.9120 - val_loss: 0.3269 - val_accuracy: 0.8890\n",
      "Epoch 23/50\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1925 - accuracy: 0.9300 - val_loss: 0.3009 - val_accuracy: 0.8996\n",
      "Epoch 24/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1743 - accuracy: 0.9357 - val_loss: 0.2976 - val_accuracy: 0.8985\n",
      "Epoch 25/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1893 - accuracy: 0.9362 - val_loss: 0.2885 - val_accuracy: 0.9074\n",
      "Epoch 26/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1545 - accuracy: 0.9399 - val_loss: 0.3440 - val_accuracy: 0.8955\n",
      "Epoch 27/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1473 - accuracy: 0.9445 - val_loss: 0.3277 - val_accuracy: 0.8999\n",
      "Epoch 28/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1355 - accuracy: 0.9461 - val_loss: 0.2792 - val_accuracy: 0.9036\n",
      "Epoch 29/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1347 - accuracy: 0.9484 - val_loss: 0.2695 - val_accuracy: 0.9084\n",
      "Epoch 30/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1993 - accuracy: 0.9365 - val_loss: 0.2627 - val_accuracy: 0.9131\n",
      "Epoch 31/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1421 - accuracy: 0.9491 - val_loss: 0.2569 - val_accuracy: 0.9060\n",
      "Epoch 32/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1415 - accuracy: 0.9475 - val_loss: 0.2676 - val_accuracy: 0.9087\n",
      "Epoch 33/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1360 - accuracy: 0.9476 - val_loss: 0.2704 - val_accuracy: 0.9026\n",
      "Epoch 34/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1399 - accuracy: 0.9494 - val_loss: 0.2379 - val_accuracy: 0.9128\n",
      "Epoch 35/50\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1204 - accuracy: 0.9528 - val_loss: 0.2583 - val_accuracy: 0.9138\n",
      "Epoch 36/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1166 - accuracy: 0.9529 - val_loss: 0.2839 - val_accuracy: 0.9046\n",
      "Epoch 37/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1182 - accuracy: 0.9514 - val_loss: 0.2969 - val_accuracy: 0.9101\n",
      "Epoch 38/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1262 - accuracy: 0.9482 - val_loss: 0.2824 - val_accuracy: 0.9131\n",
      "Epoch 39/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1434 - accuracy: 0.9431 - val_loss: 0.2971 - val_accuracy: 0.9030\n",
      "Epoch 40/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2078 - accuracy: 0.9339 - val_loss: 0.2779 - val_accuracy: 0.9125\n",
      "Epoch 41/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1277 - accuracy: 0.9528 - val_loss: 0.2871 - val_accuracy: 0.9067\n",
      "Epoch 42/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1132 - accuracy: 0.9514 - val_loss: 0.3070 - val_accuracy: 0.9009\n",
      "Epoch 43/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1122 - accuracy: 0.9528 - val_loss: 0.3194 - val_accuracy: 0.9019\n",
      "Epoch 44/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1156 - accuracy: 0.9536 - val_loss: 0.3031 - val_accuracy: 0.9094\n",
      "Epoch 45/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1554 - accuracy: 0.9422 - val_loss: 0.2960 - val_accuracy: 0.8992\n",
      "Epoch 46/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1346 - accuracy: 0.9478 - val_loss: 0.2937 - val_accuracy: 0.8985\n",
      "Epoch 47/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1242 - accuracy: 0.9499 - val_loss: 0.3036 - val_accuracy: 0.9152\n",
      "Epoch 48/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1129 - accuracy: 0.9536 - val_loss: 0.3651 - val_accuracy: 0.9050\n",
      "Epoch 49/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1145 - accuracy: 0.9543 - val_loss: 0.3209 - val_accuracy: 0.9074\n",
      "Epoch 50/50\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1221 - accuracy: 0.9495 - val_loss: 0.2928 - val_accuracy: 0.9091\n",
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 535        0         0        0                   0   \n",
      "SITTING                  0      368       121        0                   0   \n",
      "STANDING                 0       75       457        0                   0   \n",
      "WALKING                  0        0         0      483                  11   \n",
      "WALKING_DOWNSTAIRS       0        0         1        0                 417   \n",
      "WALKING_UPSTAIRS         0        0         1       18                  33   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             2  \n",
      "SITTING                            2  \n",
      "STANDING                           0  \n",
      "WALKING                            2  \n",
      "WALKING_DOWNSTAIRS                 2  \n",
      "WALKING_UPSTAIRS                 419  \n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "n_hidden = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) #an LSTM layer\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)\n",
    "\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "230/230 [==============================] - 6s 20ms/step - loss: 0.1333 - accuracy: 0.3915 - val_loss: 0.1066 - val_accuracy: 0.4852\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 4s 19ms/step - loss: 0.0972 - accuracy: 0.5103 - val_loss: 0.0930 - val_accuracy: 0.5504\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 4s 19ms/step - loss: 0.0901 - accuracy: 0.5898 - val_loss: 0.0891 - val_accuracy: 0.6573\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 4s 19ms/step - loss: 0.0758 - accuracy: 0.6840 - val_loss: 0.0726 - val_accuracy: 0.6970\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 4s 19ms/step - loss: 0.0663 - accuracy: 0.7346 - val_loss: 0.0689 - val_accuracy: 0.7133\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 5s 20ms/step - loss: 0.0605 - accuracy: 0.7661 - val_loss: 0.0630 - val_accuracy: 0.7384\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 4s 20ms/step - loss: 0.0541 - accuracy: 0.7935 - val_loss: 0.0560 - val_accuracy: 0.7587\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0509 - accuracy: 0.8051 - val_loss: 0.0551 - val_accuracy: 0.7652\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.0501 - accuracy: 0.8128 - val_loss: 0.0552 - val_accuracy: 0.7699\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 5s 20ms/step - loss: 0.0463 - accuracy: 0.8234 - val_loss: 0.0500 - val_accuracy: 0.7937\n",
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 494        0         0       17                  16   \n",
      "SITTING                 11      339       127       13                   1   \n",
      "STANDING                 0       41       473       15                   1   \n",
      "WALKING                  0        0         0      450                  26   \n",
      "WALKING_DOWNSTAIRS       0        0         0       18                 397   \n",
      "WALKING_UPSTAIRS         0        0         0      245                  40   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            10  \n",
      "SITTING                            0  \n",
      "STANDING                           2  \n",
      "WALKING                           20  \n",
      "WALKING_DOWNSTAIRS                 5  \n",
      "WALKING_UPSTAIRS                 186  \n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "n_hidden = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) #an LSTM layer\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)\n",
    "\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
